{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 6014 Final Project: Bayesian Analysis of Refugee Asylum Data\n",
    "\n",
    "- Youssef Abubaker; yaa2vb\n",
    "- Joseph Cho; jc4jx\n",
    "- Andrew J. Graves; ajg3eh\n",
    "- Gabe Yohe; gjy7kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import plotly.express as px\n",
    "\n",
    "# Format plots: Uncomment the following lines for prettier plots\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing random indices\n",
    "def get_rand_indices(df, col):\n",
    "    # Get unique values\n",
    "    unique = df[col].unique()\n",
    "    n = len(unique)\n",
    "    \n",
    "    # Get indexing mechanism\n",
    "    lookup = dict(zip(unique, range(n)))\n",
    "    out = df[col].replace(lookup).values\n",
    "    return out, n, lookup\n",
    "\n",
    "# Fucntion for wrangling model and map data\n",
    "def map_params(rand_name, is_origin=True, is_intercept=True):\n",
    "    \n",
    "    if is_origin:\n",
    "        col_str = 'origin'\n",
    "        ID = country_origin\n",
    "        lookup = country_origin_lookup\n",
    "    else:\n",
    "        col_str = 'asylum'\n",
    "        ID = country_asylum\n",
    "        lookup = country_asylum_lookup\n",
    "    \n",
    "    # Get summary statistic from trace\n",
    "    if is_intercept:\n",
    "        stat = sp.special.expit(trace[rand_name].mean(axis=0))\n",
    "    else:\n",
    "        stat = trace[rand_name].mean(axis=0)\n",
    "    # Stack stats with identifier\n",
    "    params = pd.DataFrame(np.vstack((np.unique(ID), stat)).T, columns=['lookup', 'param'])\n",
    "    # Get the country names\n",
    "    country_names = pd.concat((pd.Series(lookup).reset_index(), params), axis=1)\n",
    "    # Merge the appropriate dataframes\n",
    "    map_df = df.merge(country_names, \n",
    "                       left_on=f'Country of {col_str}', right_on='index').merge(\n",
    "                       raw_df[[f'Country of {col_str}', f'Country of {col_str} (ISO)']].drop_duplicates(), \n",
    "                                on=f'Country of {col_str}')\n",
    "    # Build final dataframe for plotting\n",
    "    plot_map_df = map_df[[f'Country of {col_str}', f'Country of {col_str} (ISO)', 'param']].drop_duplicates()\n",
    "    return plot_map_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the asylum data\n",
    "raw_df = pd.read_csv('data/asylum-decisions.csv', index_col=False)\n",
    "\n",
    "# Rename the columns\n",
    "raw_df.rename({'Recognized decisions': 'Cases_persons', \n",
    "           'Other decisions': 'Recognized decisions', \n",
    "           'Rejected decisions': 'Complementary_Protection',\n",
    "           'dec_closed': 'Rejected decisions',\n",
    "           'dec_total': 'Otherwise closed'}, axis=1, inplace=True)\n",
    "\n",
    "# Drop columns that contain NA\n",
    "df = raw_df.dropna(how='any', axis=1)\n",
    "\n",
    "# Get the outcome sums\n",
    "df = df.groupby(['Year', 'Country of origin', 'Country of asylum']).sum().reset_index()\n",
    "\n",
    "# Compute rejection rate\n",
    "df['prop_rejected'] = (df['Rejected decisions']) / (\n",
    "    df['Recognized decisions'] + df['Rejected decisions'] + \n",
    "    df['Complementary_Protection'] + df['Otherwise closed'])\n",
    "\n",
    "# Smooth 0 and 1 probabilities \n",
    "outcome = np.array(df.prop_rejected.replace({1: 1 - 1e-5, 0: 1e-5}))\n",
    "\n",
    "# Get weights by counting each decision row-wise\n",
    "weights = np.array(df[['Recognized decisions', 'Complementary_Protection', \n",
    "    'Rejected decisions', 'Otherwise closed']].sum(axis=1))\n",
    "df['weights'] = weights\n",
    "\n",
    "# Scale year\n",
    "year = (df.Year - np.mean(df.Year)) / np.std(df.Year)\n",
    "\n",
    "# Get indexers for random intercepts and random slopes\n",
    "country_origin, n_country_origin, country_origin_lookup = get_rand_indices(df, 'Country of origin')\n",
    "country_asylum, n_country_asylum, country_asylum_lookup = get_rand_indices(df, 'Country of asylum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(origin, asylum, n_origin, n_asylum):\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # Initialize prior lists\n",
    "        prior_mu = []\n",
    "        prior_sd = []\n",
    "        rand_efs = []\n",
    "        \n",
    "        # Specify random effects labels\n",
    "        labs = ['Random Intercept Origin', 'Random Intercept Asylum',\n",
    "                'Random Slope Origin', 'Random Slope Asylum']\n",
    "\n",
    "        # Priors for random intercepts and slopes\n",
    "        for i in range(4):\n",
    "            if not i % 2:\n",
    "                shape = n_origin\n",
    "            else:\n",
    "                shape = n_asylum\n",
    "            prior_mu.append(pm.Normal(f'Prior mean {i}', mu=0, sd=sp.special.logit(outcome).std()*10))\n",
    "            prior_sd.append(pm.HalfCauchy(f'Prior sd {i}', 10))\n",
    "            rand_efs.append(pm.Normal(f'{labs[i]}', \n",
    "                                      mu=prior_mu[i], sd=prior_sd[i], shape=shape))\n",
    "\n",
    "        # Fit random slopes and intercepts for country of origin and asylum\n",
    "        mu = rand_efs[0][origin] + rand_efs[1][asylum] + rand_efs[2][origin]*year + rand_efs[3][asylum]*year\n",
    "        \n",
    "        # Model error\n",
    "        eps = pm.HalfCauchy('Model Error', 10)\n",
    "\n",
    "        # Fit a Gaussian likelihood on a weighted logit of the rejection rates\n",
    "        Y = pm.Potential('Weighted Logit Rejection Rates', \n",
    "                         weights*pm.Normal.dist(mu=mu, sd=eps).logp(sp.special.logit(outcome)))\n",
    "\n",
    "        # Run ADVI\n",
    "        approx = pm.fit(15000, method='advi', random_seed=100)\n",
    "\n",
    "    return model, approx\n",
    "\n",
    "# Fit random intercpets and slopes for each country of origin / asylum\n",
    "mod, mf_approx = fit_model(country_origin, country_asylum, n_country_origin, n_country_asylum)\n",
    "\n",
    "# Save the graphical model\n",
    "g = pm.model_to_graphviz(mod)\n",
    "g.render(\"graphname\", format='pdf', cleanup=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ELBO convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(mf_approx.hist.shape[0]), -mf_approx.hist)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('ELBO')\n",
    "plt.title('Optimization process for variational inference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mod:\n",
    "    # Sample the posterior\n",
    "    trace = mf_approx.sample(5000)\n",
    "    az.plot_trace(trace, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters in probability space\n",
    "stat = sp.special.expit((trace['Random Intercept Asylum'])).mean(axis=0)\n",
    "params = pd.DataFrame(np.vstack((np.unique(country_asylum), stat)).T, \n",
    "                      columns=['lookup', 'param'])\n",
    "country_names = pd.concat((pd.Series(country_asylum_lookup).reset_index(), params), \n",
    "                          axis=1)\n",
    "params = country_names[['index', 'param']].sort_values('index')\n",
    "\n",
    "# Get weighted means\n",
    "wm = lambda x: np.average(x, weights=df.loc[x.index, 'weights'])\n",
    "weighted_means = pd.DataFrame(df.groupby('Country of asylum').prop_rejected.agg(wm)).reset_index()\n",
    "comps = params.merge(weighted_means, left_on='index', right_on='Country of asylum')\n",
    "\n",
    "# Check correlation between estimated probabilities and condtional weighted means\n",
    "comps.corr().iloc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trajectory for all countries\n",
    "all_years = df.groupby('Year').prop_rejected.mean().reset_index()\n",
    "sns.regplot(x='Year', y='prop_rejected', data=all_years)\n",
    "plt.title('Rejection rates have globally decreased over the last 20 years')\n",
    "plt.xticks(np.arange(2000, 2019, 2))\n",
    "plt.ylabel('Probability of Rejection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trajectory for Denmark\n",
    "all_years = df.query(\"`Country of asylum` == 'Denmark' & Year > 2009\").groupby('Year').prop_rejected.mean().reset_index()\n",
    "sns.regplot(x='Year', y='prop_rejected', data=all_years)\n",
    "plt.title('Denmark rejection rates have slowly crept upwards')\n",
    "plt.xticks(np.arange(2010, 2019, 2))\n",
    "plt.ylabel('Probability of Rejection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot random intercepts for origin\n",
    "fig = px.choropleth(map_params('Random Intercept Origin'), \n",
    "                    locations='Country of origin (ISO)',\n",
    "                    color='param',\n",
    "                    labels={'param': 'Intercept'},\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "                    title = 'Mapping probability of rejection across countries of origin')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot random intercepts for asylum\n",
    "fig = px.choropleth(map_params('Random Intercept Asylum', is_origin=False), \n",
    "                    locations='Country of asylum (ISO)',\n",
    "                    color='param',\n",
    "                    labels={'param': 'Intercept'},\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "                    title = 'Mapping probability of rejection across countries of asylum')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot random slopes for origin\n",
    "fig = px.choropleth(map_params('Random Slope Origin', is_intercept=False), \n",
    "                    locations='Country of origin (ISO)',\n",
    "                    color='param',\n",
    "                    labels={'param': 'Slope'},\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "                    title = 'Mapping latent rate of change for rejection rates across countries of origin')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot random slopes for asylum\n",
    "fig = px.choropleth(map_params('Random Slope Asylum', is_origin=False, is_intercept=False), \n",
    "                    locations='Country of asylum (ISO)',\n",
    "                    color='param',\n",
    "                    labels={'param': 'Slope'},\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "                    title = 'Mapping latent rate of change for rejection rates across countries of asylum')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
